@article{Newman1999,
abstract = {This book provides an introduction to Monte Carlo simulations in classical statistical physics and is aimed both at students beginning work in the field and at more experienced researchers who wish to learn more about Monte Carlo methods. It includes methods for both equilibrium and out of equilibrium systems, and discusses in detail such common algorithms as the Metropolis and heat-bath algorithms, as well as more sophisticated ones such as continuous time Monte Carlo, cluster algorithms, multigrid methods, entropic sampling and simulated tempering. Data analysis techniques are also explained starting with straightforward measurement and error-estimation techniques and progressing to topics such as the single and multiple histogram methods and finite size scaling. The last few chapters of the book are devoted to implementation issues, including lattice representations, efficient implementation of data structures, multispin coding, parallelization of Monte Carlo algorithms, and random number generation. The book also includes example programs which show how to apply these techniques to a variety of well-known models.},
author = {Newman, Mej and Barkema, Gt},
file = {:Users/ilguyi/Dropbox/앱/Mendeley/1999/Newman, Barkema/1999 - Newman, Barkema - Monte Carlo Methods in Statistical Physics.pdf:pdf},
isbn = {978-0-19-851797-9},
pages = {496},
title = {{Monte Carlo Methods in Statistical Physics}},
url = {http://global.oup.com/academic/product/monte-carlo-methods-in-statistical-physics-9780198517979;jsessionid=6390B822300F1BB12A0B0173949B9515?cc=us{\&}lang=en{\&}},
year = {1999}
}

@book{Sutton2018,
author = {Sutton, Richard S. and Barto, Andrew G.},
file = {:Users/ilguyi/Dropbox/앱/Mendeley/2018/Sutton, Barto/2018 - Sutton, Barto - Reinforcement Learning An Introduction.pdf:pdf},
isbn = {9780262193986},
title = {{Reinforcement Learning: An Introduction}},
year = {2018}
}

@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M CM Christopher M.},
booktitle = {Pattern Recognition},
doi = {10.1117/1.2819119},
eprint = {0-387-31073-8},
file = {:Users/ilguyi/Dropbox/앱/Mendeley/2006/Bishop/2006 - Bishop - Pattern Recognition and Machine Learning.pdf:pdf},
isbn = {978-0387310732},
issn = {10179909},
number = {4},
pages = {738},
pmid = {8943268},
title = {{Pattern Recognition and Machine Learning}},
url = {http://soic.iupui.edu/syllabi/semesters/4142/INFO{\_}B529{\_}Liu{\_}s.pdf{\%}5Cnhttp://www.library.wisc.edu/selectedtocs/bg0137.pdf{\%}5Cnhttp://www.library.wisc.edu/selectedtocs/bg0137.pdf},
volume = {4},
year = {2006}
}

@book{James2000,
abstract = {3'-Azido-2',3'-dideoxythymidine (AZT, 1, zidovudine, RetrovirTM) is used to treat patients with human immunodeficiency virus (HIV) infection. AZT, after conversion to AZT-5'-triphosphate (AZT-TP) by cellular enzymes, inhibits HIV-reverse transcriptase (HIV-RT). The major clinical limitations of AZT are due to clinical toxicities that include bone marrow suppression, hepatic abnormalities and myopathy, absolute dependence on host cell kinase-mediated activation which leads to low activity, limited brain uptake, a short half-life of about one hour in plasma that dictates frequent administration to maintain therapeutic drug levels, low potential for metabolic activation and/or high susceptibility to catabolism, and the rapid development of resistance by HIV-1. These limitations have prompted the development of strategies for designing prodrugs of AZT. A variety of 5'-O-substituted prodrugs of AZT constitute the subject of this review. The drug-design rationale on which these approaches are based is that the ester conjugate will be converted by hydrolysis and/or enzymatic cleavage to AZT or its 5{\&}prime;-monophosphate (AZT-MP). Most prodrug derivatives of AZT have been prepared by derivatization of AZT at its 5'-O position to provide two prominent classes of compounds that encompass: A) 5'-O-carboxylic esters derived from 1) cyclic 5'-O-carboxylic acids such as steroidal 17b-carboxylic acids, 1-adamantanecarboxylic acid, bicyclam carboxylic acid derivatives, O-acetylsalicylic acid, and carbohydrate derivatives, 2) amino acids, 3) 1, 4-dihydro-1-methyl-3-pyridinylcarboxylic acid, 4) aliphatic fatty acid analogs such as myristic acid containing a heteroatom, or without a heteroatom such as stearic acid, and 5) long chain polyunsaturated fatty acid analogs such as retinoic acid, and B) masked phosphates such as 1) phosphodiesters that include monoalkyl or monoaryl phosphate, carbohydrate, ether lipid, ester lipid, and foscarnet derivatives, 2) a variety of phosphotriesters that include dialkylphosphotriesters, diarylphosphotriesters, glycolate and lactate phosphotriesters, phosphotriester approaches using simultaneous enzymatic and chemical hydrolysis of bis(4-acyloxybenzyl) esters, bis(S-acyl-2-thioethyl) (SATE) esters, cyclosaligenyl prodrugs, glycosyl phosphotriesters, and steroidal phosphotriesters, 3) phosphoramidate derivatives, 4) dinucleoside phosphate derivatives that possess a second anti-HIV moiety such as AZT-P-ddA, AZT-P-ddI, AZTP2AZT, AZTP2ACV), and 5) 5'-hydrogen phosphonate and 5'-methylene phosphonate derivatives of AZT. In these prodrugs, the conjugating moiety is linked to AZT via a 5'-O-ester or 5'-O-phosphate group. 5'-O-Substituted AZT prodrugs have been designed with the objectives of improving anti-HIV activity, enhancing blood-brain barrier penetration, modifying pharmacokinetic properties to increase plasma half-life and improving drug delivery with respect to site-specific targeting or drug localization. Bypassing the first phosphorylation step, regulating transport and conferring sustained release of AZT prolong its duration of action, decrease toxicity and improve patient acceptability. The properties of these prodrugs and their anti-HIV activities are now reviewed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
booktitle = {Current medicinal chemistry},
doi = {10.1007/978-1-4614-7138-7},
eprint = {arXiv:1011.1669v3},
file = {:Users/ilguyi/Dropbox/앱/Mendeley/2000/James et al/2000 - James et al. - An introduction to Statistical Learning.pdf:pdf},
isbn = {978-1-4614-7137-0},
issn = {0929-8673},
number = {10},
pages = {995--1039},
pmid = {10911016},
title = {{An introduction to Statistical Learning}},
volume = {7},
year = {2000}
}

@article{Hastie2001,
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come a vast amount of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics.},
archivePrefix = {arXiv},
arxivId = {1010.3003},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
doi = {10.1198/jasa.2004.s339},
eprint = {1010.3003},
file = {:Users/ilguyi/Dropbox/앱/Mendeley/2001/Hastie, Tibshirani, Friedman/2001 - Hastie, Tibshirani, Friedman - The Elements of Statistical Learning.pdf:pdf},
isbn = {978-0-387-84857-0},
issn = {03436993},
journal = {The Mathematical Intelligencer},
keywords = {inger series in statistics},
number = {2},
pages = {83--85},
pmid = {21196786},
title = {{The Elements of Statistical Learning}},
url = {http://www.springerlink.com/index/D7X7KX6772HQ2135.pdf{\%}255Cnhttp://www-stat.stanford.edu/{~}tibs/book/preface.ps},
volume = {27},
year = {2001}
}

@book{NikhilKetkar2017,
author = {{Nikhil Ketkar}},
file = {:Users/ilguyi/Dropbox/앱/Mendeley/2017/Nikhil Ketkar/2017 - Nikhil Ketkar - Deep Learning with Python.pdf:pdf},
isbn = {9781617294433},
title = {{Deep Learning with Python}},
year = {2017}
}

@article{Nie2014,
author = {Nie, Jian-yun and Eds, Yansong Feng},
file = {:Users/ilguyi/Dropbox/앱/Mendeley/2014/Nie, Eds/2014 - Nie, Eds - Natural Language Processing.pdf:pdf},
isbn = {9783662459232},
title = {{Natural Language Processing}},
year = {2014}
}

@article{Barber2010,
abstract = {Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Barber, David},
doi = {10.1017/CBO9780511804779},
eprint = {arXiv:1011.1669v3},
file = {:Users/ilguyi/Dropbox/앱/Mendeley/2010/Barber/2010 - Barber - Bayesian Reasoning And Machine Learning.pdf:pdf},
isbn = {9780521518147},
issn = {9780521518147},
keywords = {Computational,Information-Theoretic Learning with,Learning/Statistics {\&} Optimisation,Theory {\&} Algorithms},
pages = {610},
pmid = {16931139},
title = {{Bayesian Reasoning And Machine Learning}},
year = {2010}
}

@article{Goodfellow2015,
abstract = {www.deeplearningbook.org},
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
file = {:Users/ilguyi/Dropbox/앱/Mendeley/2015/Goodfellow, Bengio, Courville/2015 - Goodfellow, Bengio, Courville - Deep Learning.pdf:pdf},
journal = {deeplearningbook},
title = {{Deep Learning}},
year = {2015}
}
