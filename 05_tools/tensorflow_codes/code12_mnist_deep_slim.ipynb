{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST convolutional neural networks with slim\n",
    "\n",
    "* MNIST data를 가지고 **convolutional neural networks**를 만들어보자.\n",
    "  * [참고: TensorFlow.org](https://www.tensorflow.org/get_started/mnist/pros)\n",
    "  * [소스: mnist_deep.py](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/mnist/mnist_deep.py)를 slim을 이용하여 수정함\n",
    "  * [`tf.contrib.slim` 참고](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A deep MNIST classifier using convolutional layers.\n",
    "See extensive documentation at\n",
    "https://www.tensorflow.org/get_started/mnist/pros\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "tf.set_random_seed(219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../mnist'\n",
    "mnist = input_data.read_data_sets(data_dir, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 999\n",
    "print(\"label = \", np.argmax(mnist.train.labels[index]))\n",
    "plt.imshow(mnist.train.images[index].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "\n",
    "* [`tf.contrib.layers`](https://www.tensorflow.org/api_guides/python/contrib.layers)\n",
    "* [`tf.contrib.layers.conv2d`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/conv2d)\n",
    "* [`tf.contrib.layers.max_pool2d`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/max_pool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnn_slim(x):\n",
    "  \"\"\"deepnn builds the graph for a deep net for classifying digits.\n",
    "  Args:\n",
    "    x: an input tensor with the dimensions (N_examples, 784), where 784 is the\n",
    "    number of pixels in a standard MNIST image.\n",
    "  Returns:\n",
    "    A tuple (y, keep_prob). y is a tensor of shape (N_examples, 10), with values\n",
    "    equal to the logits of classifying the digit into one of 10 classes (the\n",
    "    digits 0-9). keep_prob is a scalar placeholder for the probability of\n",
    "    dropout.\n",
    "  \"\"\"\n",
    "  # Reshape to use within a convolutional neural net.\n",
    "  # Last dimension is for \"features\" - there is only one here, since images are\n",
    "  # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "  with tf.name_scope('reshape'):\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "  # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "  h_conv1 = slim.conv2d(x_image, 32, [5, 5], scope='conv1')\n",
    "\n",
    "  # Pooling layer - downsamples by 2X.\n",
    "  h_pool1 = slim.max_pool2d(h_conv1, [2, 2], scope='pool1')\n",
    "\n",
    "  # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "  h_conv2 = slim.conv2d(h_pool1, 64, [5, 5], scope='conv2')\n",
    "\n",
    "  # Second pooling layer.\n",
    "  h_pool2 = slim.max_pool2d(h_conv2, [2, 2], scope='pool2')\n",
    "\n",
    "  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "  # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "  h_pool2_flat = slim.flatten(h_pool2, scope='flatten')\n",
    "  h_fc1 = slim.fully_connected(h_pool2_flat, 1024, scope='fc1')\n",
    "\n",
    "  # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "  # features.\n",
    "  keep_prob = tf.placeholder(tf.float32)\n",
    "  h_fc1_drop = slim.dropout(h_fc1, keep_prob, scope='dropout')\n",
    "\n",
    "  # Map the 1024 features to 10 classes, one for each digit\n",
    "  y_conv = slim.fully_connected(h_fc1_drop, 10, activation_fn=None, scope='fc2')\n",
    "    \n",
    "  return y_conv, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model and define loss and optimizer\n",
    "\n",
    "* [`tf.losses.softmax_cross_entropy`](https://www.tensorflow.org/api_docs/python/tf/losses/softmax_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph for the deep net\n",
    "y_conv, keep_prob = deepnn_slim(x)\n",
    "\n",
    "#with tf.name_scope('loss'):\n",
    "#  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n",
    "#                                                          logits=y_conv)\n",
    "#cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_,\n",
    "                                                logits=y_conv,\n",
    "                                                scope='loss')\n",
    "\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "  train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "  correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "  correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "graph_location = 'graphs/code12_mnist_slim'\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Session() and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "max_step = 100\n",
    "for step in range(max_step+1):\n",
    "  batch = mnist.train.next_batch(32)\n",
    "  feed_dict_train = {x: batch[0],\n",
    "                     y_: batch[1],\n",
    "                     keep_prob: 0.5}\n",
    "  feed_dict_eval = {x: batch[0],\n",
    "                    y_: batch[1],\n",
    "                    keep_prob: 1.0}\n",
    "  _, ce = sess.run([train_step, cross_entropy], feed_dict=feed_dict_train)\n",
    "  if step % 10 == 0:\n",
    "    train_accuracy = sess.run(accuracy, feed_dict=feed_dict_eval)\n",
    "    print('step %d, training accuracy %g, cross_entropy %g' % (step, train_accuracy, ce))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trained model\n",
    "\n",
    "* test accuracy: 0.8308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test accuracy %g' % sess.run(accuracy, feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test images inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "test_batch_size = 16\n",
    "batch_xs, _ = mnist.test.next_batch(test_batch_size)\n",
    "y_pred = sess.run(y_conv, feed_dict={x: batch_xs, keep_prob: 1.0})\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  p.set_title(\"y_pred: {}\".format(np.argmax(py)))\n",
    "  p.imshow(px.reshape(28, 28), cmap='gray')\n",
    "  p.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직접 실습\n",
    "\n",
    "* 여러가지 hyper-parameter들을 바꿔가면서 accuracy를 높혀보자"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
