{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST convolutional neural networks with slim\n",
    "\n",
    "* MNIST data를 가지고 **convolutional neural networks**를 `tf.contrib.slim`을 이용하여 만들어보자.\n",
    "  * [참고: TensorFlow slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)\n",
    "* [`tf.summary`](https://www.tensorflow.org/api_docs/python/tf/summary) 사용법을 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A deep MNIST classifier using convolutional layers.\n",
    "See extensive documentation at\n",
    "https://www.tensorflow.org/get_started/mnist/pros\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "tf.set_random_seed(219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../mnist'\n",
    "mnist = input_data.read_data_sets(data_dir, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 1000\n",
    "print(\"label = \", np.argmax(mnist.train.labels[index]))\n",
    "plt.imshow(mnist.train.images[index].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "\n",
    "* [`tf.contrib.layers`](https://www.tensorflow.org/api_guides/python/contrib.layers)\n",
    "* [`tf.contrib.layers.conv2d`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/conv2d)\n",
    "* [`tf.contrib.layers.max_pool2d`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/max_pool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnn_slim(x):\n",
    "  is_training = tf.placeholder(tf.bool)\n",
    "  batch_norm_params = {'decay': 0.9,\n",
    "                       'epsilon': 0.001,\n",
    "                       'is_training': is_training,\n",
    "                       'scope': 'batch_norm'}\n",
    "  l2_decay = 0.0001\n",
    "  \n",
    "  # Reshape to use within a convolutional neural net.\n",
    "  # Last dimension is for \"features\" - there is only one here, since images are\n",
    "  # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "  with tf.name_scope('reshape'):\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "  with slim.arg_scope([slim.conv2d],\n",
    "                      kernel_size=[5, 5],\n",
    "                      normalizer_fn=slim.batch_norm,\n",
    "                      normalizer_params=batch_norm_params,\n",
    "                      weights_regularizer=slim.l2_regularizer(l2_decay)):\n",
    "    with slim.arg_scope([slim.max_pool2d],\n",
    "                        kernel_size=[2, 2]):\n",
    "\n",
    "      # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "      conv1 = slim.conv2d(inputs=x_image, num_outputs=32, scope='conv1')\n",
    "\n",
    "      # Pooling layer - downsamples by 2X.\n",
    "      pool1 = slim.max_pool2d(inputs=conv1, scope='pool1')\n",
    "\n",
    "      # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "      conv2 = slim.conv2d(inputs=pool1, num_outputs=64, scope='conv2')\n",
    "    \n",
    "      # Second pooling layer.\n",
    "      pool2 = slim.max_pool2d(inputs=conv2, scope='pool2')\n",
    "                        \n",
    "  with slim.arg_scope([slim.fully_connected],\n",
    "                      normalizer_fn=slim.batch_norm,\n",
    "                      normalizer_params=batch_norm_params,\n",
    "                      weights_regularizer=slim.l2_regularizer(l2_decay)):\n",
    "\n",
    "    # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "    # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "    flat = slim.flatten(pool2, scope='flatten')\n",
    "\n",
    "    fc1 = slim.fully_connected(flat, num_outputs=1024, scope='fc1')\n",
    "\n",
    "    # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "    # features.\n",
    "    fc1_drop = slim.dropout(fc1, keep_prob=0.5, is_training=is_training, scope='dropout')\n",
    "\n",
    "    # Map the 1024 features to 10 classes, one for each digit\n",
    "    fc2 = slim.fully_connected(fc1_drop,\n",
    "                               num_outputs=10,\n",
    "                               activation_fn=None,\n",
    "                               scope='fc2')\n",
    "    \n",
    "  return fc2, is_training, x_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only necessary if you use IDLE or a jupyter notebook\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model and define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph for the deep net\n",
    "y_conv, is_training, x_image = deepnn_slim(x)\n",
    "\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_,\n",
    "                                                logits=y_conv,\n",
    "                                                scope='cross_entropy')\n",
    "l2_regualrization = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "with tf.name_scope('total_loss'):\n",
    "  total_loss = cross_entropy + l2_regualrization\n",
    "\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "  correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "  correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "graph_location = 'graphs/code15_mnist_summary'\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalization update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch normalization update\n",
    "batchnorm_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "# Add dependency to compute batchnorm_updates.\n",
    "with tf.control_dependencies(batchnorm_update_ops):\n",
    "  train_step = tf.train.AdamOptimizer(1e-4).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "  tf.summary.scalar('loss/cross_entropy', cross_entropy)\n",
    "  tf.summary.scalar('loss/l2_regualrization', l2_regualrization)\n",
    "  tf.summary.scalar('loss/total_loss', total_loss)\n",
    "  tf.summary.image('images', x_image)\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "  # merge all summaries\n",
    "  summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Session() and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "max_step = 100\n",
    "for step in range(max_step+1):\n",
    "  batch = mnist.train.next_batch(32)\n",
    "  feed_dict_train = {x: batch[0],\n",
    "                     y_: batch[1],\n",
    "                     is_training: True}\n",
    "  feed_dict_eval = {x: batch[0],\n",
    "                    y_: batch[1],\n",
    "                    is_training: False}\n",
    "  _, tl, ce = sess.run([train_step, total_loss, cross_entropy], feed_dict=feed_dict_train)\n",
    "  if step % 10 == 0:\n",
    "    train_accuracy = sess.run(accuracy, feed_dict=feed_dict_eval)\n",
    "    print('step %d, training accuracy %g, total_loss %g, cross_entropy %g' % (step, train_accuracy, tl, ce))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trained model\n",
    "\n",
    "* test accuracy: 0.9359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test accuracy %g' % sess.run(accuracy, feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, is_training: False}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test images inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "test_batch_size = 16\n",
    "batch_xs, _ = mnist.test.next_batch(test_batch_size)\n",
    "y_pred = sess.run(y_conv, feed_dict={x: batch_xs,\n",
    "                                     is_training: False})\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  p.set_title(\"y_pred: {}\".format(np.argmax(py)))\n",
    "  p.imshow(px.reshape(28, 28), cmap='gray')\n",
    "  p.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print all trainable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show info for trainable variables\n",
    "t_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(t_vars, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim.model_analyzer.analyze_vars(tf.global_variables(), print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim.model_analyzer.analyze_vars(tf.model_variables(), print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
