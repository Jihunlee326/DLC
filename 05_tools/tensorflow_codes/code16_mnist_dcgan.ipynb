{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN with MNIST\n",
    "\n",
    "* MNIST data를 가지고 **Deep Convolutional GAN**를 `tf.contrib.slim`을 이용하여 만들어보자.\n",
    "  * [참고: TensorFlow slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "tf.set_random_seed(219)\n",
    "np.random.seed(219)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Training Flags\n",
    "tf.app.flags.DEFINE_string('train_dir', 'train/dcgan/exp1', '')\n",
    "tf.app.flags.DEFINE_integer('max_steps', 50000, '')\n",
    "tf.app.flags.DEFINE_integer('save_steps', 10000, '')\n",
    "tf.app.flags.DEFINE_integer('summary_steps', 2000, '')\n",
    "tf.app.flags.DEFINE_integer('print_steps', 500, '')\n",
    "tf.app.flags.DEFINE_integer('batch_size', 64, '')\n",
    "tf.app.flags.DEFINE_float('learning_rate_D', 0.0002, '')\n",
    "tf.app.flags.DEFINE_float('learning_rate_G', 0.001, '')\n",
    "tf.app.flags.DEFINE_integer('k', 1, '')\n",
    "tf.app.flags.DEFINE_integer('num_samples', 10, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../mnist'\n",
    "mnist = input_data.read_data_sets(data_dir, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN_model(object):\n",
    "  \"\"\"Deep Convolutional Generative Adversarial Networks\n",
    "  implementation based on http://arxiv.org/abs/1511.06434\n",
    "  \n",
    "  \"Unsupervised Representation Learning with\n",
    "  Deep Convolutional Generative Adversarial Networks\"\n",
    "  Alec Radford, Luke Metz and Soumith Chintala\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, mode):\n",
    "    \"\"\"Basic setup.\n",
    "    \n",
    "    Args:\n",
    "      mode: \"train\" or \"generate\"\n",
    "    \"\"\"\n",
    "    assert mode in [\"train\", \"generate\"]\n",
    "    self.mode = mode\n",
    "    \n",
    "    # hyper-parameters for model\n",
    "    self.x_dim = 784\n",
    "    self.z_dim = 100\n",
    "    self.batch_size = FLAGS.batch_size\n",
    "    self.num_samples = FLAGS.num_samples\n",
    "    \n",
    "    # Global step Tensor.\n",
    "    self.global_step = None\n",
    "    \n",
    "    print('The mode is %s.' % self.mode)\n",
    "    print('complete initializing model.')\n",
    "    \n",
    "    \n",
    "  def build_inputs(self):\n",
    "    \"\"\"Build random_z.\n",
    "    \n",
    "    Returns:\n",
    "      A float32 Tensor with [batch_size, 1, 1, z_dim]\n",
    "    \"\"\"\n",
    "    # Setup variable of random vector z\n",
    "    with tf.variable_scope('random_z'):\n",
    "      self.random_z = tf.placeholder(tf.float32, [None, self.z_dim])\n",
    "\n",
    "    return self.random_z\n",
    "  \n",
    "  \n",
    "  def read_MNIST(self):\n",
    "    # Setup placeholder of real data (MNIST)\n",
    "    with tf.variable_scope('mnist'):\n",
    "      self.mnist = tf.placeholder(tf.float32, [None, self.x_dim])\n",
    "      self.mnist_image = tf.reshape(self.mnist, [-1, 28, 28, 1])\n",
    "      \n",
    "      return self.mnist_image\n",
    "\n",
    "\n",
    "  def Generator(self, random_z, is_training=True, reuse=False):\n",
    "    \"\"\"Generator setup.\n",
    "    \n",
    "    Args:\n",
    "      random_z: A float32 Tensor random vector (latent code)\n",
    "      is_training: boolean whether training mode or generating mode\n",
    "      reuse: reuse flag\n",
    "      \n",
    "    Returns:\n",
    "      A float32 scalar Tensor of generated images from random vector\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('Generator') as scope:\n",
    "      if reuse:\n",
    "        scope.reuse_variables()\n",
    "\n",
    "      batch_norm_params = {'decay': 0.9,\n",
    "                           'epsilon': 0.001,\n",
    "                           'is_training': is_training,\n",
    "                           'scope': 'batch_norm'}\n",
    "      with slim.arg_scope([slim.conv2d_transpose],\n",
    "                          kernel_size=[4, 4],\n",
    "                          stride=[2, 2],\n",
    "                          normalizer_fn=slim.batch_norm,\n",
    "                          normalizer_params=batch_norm_params):\n",
    "\n",
    "        # Use full conv2d_transpose instead of projection and reshape\n",
    "        # random_z: 100 dim\n",
    "        self.inputs = tf.reshape(random_z, [-1, 1, 1, self.z_dim])\n",
    "        # inputs = 1 x 1 x 100 dim\n",
    "        self.layer1 = slim.conv2d_transpose(inputs=self.inputs,\n",
    "                                            num_outputs=256,\n",
    "                                            kernel_size=[3, 3],\n",
    "                                            padding='VALID',\n",
    "                                            scope='layer1')\n",
    "        # layer1: 3 x 3 x 256 dim\n",
    "        self.layer2 = slim.conv2d_transpose(inputs=self.layer1,\n",
    "                                            num_outputs=128,\n",
    "                                            kernel_size=[3, 3],\n",
    "                                            padding='VALID',\n",
    "                                            scope='layer2')\n",
    "        # layer2: 7 x 7 x 128 dim\n",
    "        self.layer3 = slim.conv2d_transpose(inputs=self.layer2,\n",
    "                                            num_outputs=64,\n",
    "                                            scope='layer3')\n",
    "        # layer3: 14 x 14 x 64 dim\n",
    "        self.layer4 = slim.conv2d_transpose(inputs=self.layer3,\n",
    "                                            num_outputs=1,\n",
    "                                            normalizer_fn=None,\n",
    "                                            activation_fn=tf.sigmoid,\n",
    "                                            scope='layer4')\n",
    "        # output = layer4: 28 x 28 x 1 dim\n",
    "        generated_data = self.layer4\n",
    "\n",
    "        return generated_data\n",
    "    \n",
    "    \n",
    "  def Discriminator(self, data, reuse=False):\n",
    "    \"\"\"Discriminator setup.\n",
    "    \n",
    "    Args:\n",
    "      data: A float32 scalar Tensor of real data\n",
    "      reuse: reuse flag\n",
    "      \n",
    "    Returns:\n",
    "      logits: A float32 scalar Tensor\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('Discriminator') as scope:\n",
    "      if reuse:\n",
    "        scope.reuse_variables()\n",
    "        \n",
    "      batch_norm_params = {'decay': 0.9,\n",
    "                           'epsilon': 0.001,\n",
    "                           'scope': 'batch_norm'}\n",
    "      with slim.arg_scope([slim.conv2d],\n",
    "                          kernel_size=[4, 4],\n",
    "                          stride=[2, 2],\n",
    "                          activation_fn=tf.nn.leaky_relu,\n",
    "                          normalizer_fn=slim.batch_norm,\n",
    "                          normalizer_params=batch_norm_params):\n",
    "\n",
    "        # data: 28 x 28 x 1 dim\n",
    "        self.layer1 = slim.conv2d(inputs=data,\n",
    "                                  num_outputs=64,\n",
    "                                  normalizer_fn=None,\n",
    "                                  scope='layer1')\n",
    "        # layer1: 14 x 14 x 64 dim\n",
    "        self.layer2 = slim.conv2d(inputs=self.layer1,\n",
    "                                  num_outputs=128,\n",
    "                                  scope='layer2')\n",
    "        # layer2: 7 x 7 x 128 dim\n",
    "        self.layer3 = slim.conv2d(inputs=self.layer2,\n",
    "                                  num_outputs=256,\n",
    "                                  kernel_size=[3, 3],\n",
    "                                  padding='VALID',\n",
    "                                  scope='layer3')\n",
    "        # layer3: 3 x 3 x 256 dim\n",
    "        self.layer4 = slim.conv2d(inputs=self.layer3,\n",
    "                                  num_outputs=1,\n",
    "                                  kernel_size=[3, 3],\n",
    "                                  stride=[1, 1],\n",
    "                                  padding='VALID',\n",
    "                                  normalizer_fn=None,\n",
    "                                  activation_fn=None,\n",
    "                                  scope='layer4')\n",
    "        # logits = layer4: 1 x 1 x 1 dim\n",
    "        discriminator_logits = tf.squeeze(self.layer4, axis=[1, 2])\n",
    "\n",
    "        return discriminator_logits\n",
    "    \n",
    "    \n",
    "  def setup_global_step(self):\n",
    "    \"\"\"Sets up the global step Tensor.\"\"\"\n",
    "    if self.mode == \"train\":\n",
    "      self.global_step = tf.Variable(initial_value=0,\n",
    "                                     name='global_step',\n",
    "                                     trainable=False,\n",
    "                                     collections=[tf.GraphKeys.GLOBAL_STEP,\n",
    "                                                  tf.GraphKeys.GLOBAL_VARIABLES])\n",
    "      \n",
    "      print('complete setup global_step.')\n",
    "      \n",
    "      \n",
    "  def GANLoss(self, logits, is_real=True, scope=None):\n",
    "    \"\"\"Computes standard GAN loss between `logits` and `labels`.\n",
    "    \n",
    "    Args:\n",
    "      logits: A float32 Tensor of logits.\n",
    "      is_real: boolean, Treu means `1` labeling, False means `0` labeling.\n",
    "      \n",
    "    Returns:\n",
    "      A scalar Tensor representing the loss value.\n",
    "    \"\"\"\n",
    "    if is_real:\n",
    "      labels = tf.ones_like(logits)\n",
    "    else:\n",
    "      labels = tf.zeros_like(logits)\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=labels,\n",
    "                                           logits=logits,\n",
    "                                           scope=scope)\n",
    "\n",
    "    return loss\n",
    "\n",
    "      \n",
    "  def build(self):\n",
    "    \"\"\"Creates all ops for training or generate.\"\"\"\n",
    "    self.setup_global_step()\n",
    "    \n",
    "    \n",
    "    if self.mode == \"generate\":\n",
    "      pass\n",
    "    \n",
    "    else:\n",
    "      # generating random vector\n",
    "      self.random_z = self.build_inputs()\n",
    "      # generating images from Generator() via random vector z\n",
    "      self.generated_data = self.Generator(self.random_z)\n",
    "      \n",
    "      # read dataset\n",
    "      self.real_data = self.read_MNIST()\n",
    "      \n",
    "      # discriminating real data by Discriminator()\n",
    "      self.real_logits = self.Discriminator(self.real_data)\n",
    "      # discriminating fake data (generated)_images) by Discriminator()\n",
    "      self.fake_logits = self.Discriminator(self.generated_data, reuse=True)\n",
    "      \n",
    "      # losses of real with label \"1\"\n",
    "      self.loss_real = self.GANLoss(logits=self.real_logits, is_real=True, scope='loss_D_real')\n",
    "      # losses of fake with label \"0\"\n",
    "      self.loss_fake = self.GANLoss(logits=self.fake_logits, is_real=False, scope='loss_D_fake')\n",
    "      \n",
    "      # losses of Discriminator\n",
    "      with tf.variable_scope('loss_D'):\n",
    "        self.loss_Discriminator = self.loss_real + self.loss_fake\n",
    "      # losses of Generator with label \"1\" that used to fool the Discriminator\n",
    "      self.loss_Generator = self.GANLoss(logits=self.fake_logits, is_real=True, scope='loss_G')\n",
    "      \n",
    "      # Separate variables for each function\n",
    "      self.D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Discriminator')\n",
    "      self.G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Generator')\n",
    "      \n",
    "      \n",
    "      # generating images for sample\n",
    "      self.sample_data = self.Generator(self.random_z, is_training=False, reuse=True)\n",
    "\n",
    "      # write summaries\n",
    "      tf.summary.scalar('losses/loss_Discriminator', self.loss_Discriminator)\n",
    "      tf.summary.scalar('losses/loss_Generator', self.loss_Generator)\n",
    "      \n",
    "      tf.summary.image('random_images', self.generated_data, max_outputs=4)\n",
    "      #tf.summary.image('real_images', self.real_data)\n",
    "      \n",
    "    print('complete model build.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_data(sample_data, max_print=FLAGS.num_samples):\n",
    "  print_images = sample_data[:max_print,:]\n",
    "  print_images = print_images.reshape([max_print, 28, 28])\n",
    "  print_images = print_images.swapaxes(0, 1)\n",
    "  print_images = print_images.reshape([28, max_print * 28])\n",
    "  \n",
    "  plt.figure(figsize=(max_print, 1))\n",
    "  plt.axis('off')\n",
    "  plt.imshow(print_images, cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DCGAN_model(mode=\"train\")\n",
    "model.build()\n",
    "\n",
    "# show info for trainable variables\n",
    "t_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(t_vars, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_D = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate_D, beta1=0.5)\n",
    "opt_G = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate_G, beta1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "  opt_D_op = opt_D.minimize(model.loss_Discriminator, var_list=model.D_vars)\n",
    "  opt_G_op = opt_G.minimize(model.loss_Generator, global_step=model.global_step,\n",
    "                            var_list=model.G_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=1000)\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "sv = tf.train.Supervisor(logdir=FLAGS.train_dir,\n",
    "                         summary_op=None,\n",
    "                         saver=saver,\n",
    "                         save_model_secs=0,\n",
    "                         init_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "with sv.managed_session(config=sess_config) as sess:\n",
    "  tf.logging.info('Start Session.')\n",
    "  \n",
    "  #sv.start_queue_runners(sess=sess)\n",
    "  #tf.logging.info('Starting Queues.')\n",
    "\n",
    "  # save loss values for plot\n",
    "  losses = []\n",
    "  for _ in range(FLAGS.max_steps+1):\n",
    "    start_time = time.time()\n",
    "    if sv.should_stop():\n",
    "      break\n",
    "    \n",
    "    for _ in range(FLAGS.k):\n",
    "      mnist_batch = mnist.train.next_batch(FLAGS.batch_size)\n",
    "      random_z = np.random.uniform(low=-1., high=1., size=[FLAGS.batch_size, model.z_dim])\n",
    "\n",
    "      _, loss_D = sess.run([opt_D_op, model.loss_Discriminator],\n",
    "                            feed_dict={model.mnist: mnist_batch[0],\n",
    "                                       model.random_z: random_z})\n",
    "    _, _global_step, loss_G = sess.run([opt_G_op,\n",
    "                                        sv.global_step,\n",
    "                                        model.loss_Generator],\n",
    "                                        feed_dict={model.mnist: mnist_batch[0],\n",
    "                                                   model.random_z: random_z})\n",
    "\n",
    "    epochs = _global_step * FLAGS.batch_size / len(mnist.train.labels)\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    if _global_step % FLAGS.print_steps == 0:\n",
    "      examples_per_sec = FLAGS.batch_size / float(duration)\n",
    "      print(\"Epochs: %.2f global step: %d  loss_D: %g  loss_G: %g (%.1f examples/sec; %.1f sec/batch)\"\n",
    "              % (epochs, _global_step, loss_D, loss_G, examples_per_sec, duration))\n",
    "      \n",
    "      losses.append([epochs, loss_D, loss_G])\n",
    "      \n",
    "      # print sample data\n",
    "      sample_random_z = np.random.uniform(low=-1., high=1., size=[FLAGS.num_samples, model.z_dim])\n",
    "      sample_data = sess.run(model.sample_data, feed_dict={model.random_z: sample_random_z})\n",
    "      print_sample_data(sample_data)\n",
    "      \n",
    "    if _global_step % FLAGS.summary_steps == 0:\n",
    "      summary_str = sess.run(summary_op, feed_dict={model.mnist: mnist_batch[0],\n",
    "                                                    model.random_z: random_z})\n",
    "      sv.summary_computed(sess, summary_str)\n",
    "      \n",
    "    if _global_step % FLAGS.save_steps == 0:\n",
    "      tf.logging.info('Saving model with global step %d to disk.' % _global_step)\n",
    "      sv.saver.save(sess, sv.save_path, global_step=sv.global_step)\n",
    "      \n",
    "  tf.logging.info('complete training...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.asarray(losses)\n",
    "\n",
    "plt.plot(losses[:,0], losses[:,1], label='loss_D')\n",
    "plt.plot(losses[:,0], losses[:,2], label='loss_G')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
